ChatGPT網用戶界面，許多人使用它來完成特定且經常是一次性的任務。
但我認為作為開發人員，LLM大型語言模型的威力在於使用API調用LLM，快速構建軟件應用程序。
事實上，我所在的AI Fund團隊在應用這些技術到許多不同的應用程序方面與眾多初創企業合作，看到LLM API可以讓開發人員非常快速地構建應用程序，這非常令人興奮。
因此，在本課程中，我們將與您分享您可以執行的一些可能性以及如何執行它們的最佳實踐。
要涵蓋的材料很多。
首先，您會學習一些軟件開發的提示最佳實踐。
然後，我們將介紹一些常見用例，例如總結、推斷、轉換和擴展，然後您將使用LLM構建一個聊天機器人。
我們希望這可以激發您對新應用程序的想象力。
在開發大型語言模型或LLMs方面，大體上有兩種類型的LLMs，我稱之為基礎LLMs和指令調整LLMs。
基礎LLMs已經被訓練根據文本訓練數據預測下一個詞，通常是受大量來自網際網路和其他來源的數據訓練，以找出下一個最有可能的詞是什麼。
例如，如果您提示「從前從前有一頭獨角獸」，它可能會繼續預測：「與所有獨角獸朋友一起生活在神奇的森林中」。
但如果您提示「法國的首都是什麼」，基於網絡文章所可能具有的內容，基礎LLMs很可能會完成這個提示「法國人口最多的城市是什麼，法國的人口是多少」，因為網絡文章可能很可能是有關法國的測試問題列表。
相比之下，在指令調整LLMs中，許多研究與實踐的動力都被投入其中。
指令調整LLMs已經過訓練，可以按照指令執行。
因此，如果您問它「法國的首都是什麼？」，它更有可能輸出類似法國的首都是巴黎這樣的答案。
指令調整LLMs的訓練方法通常是從基礎LLMs開始，基礎LLMs已經過多數文本數據的訓練。
然後進一步進行微調，使用輸入和輸出作為指令和優秀的嘗試來遵循這些指令，通常使用一種叫做RLHF的人類反饋強化學習技術來進一步優化，使系統更能夠幫助和遵循指令。
因為指令調整LLMs已經過訓練，可以幫助、誠實且無害的，例如，它們輸出的毒性文本比基礎LLMs要少得多。
許多實際使用情境已經轉向指令調整LLMs。
您在網絡上找到的一些最佳實踐可能更適合於基礎LLM。
但對於大多數實際應用程序，我們建議大多數人都將注意力集中在指令調整LLMs上，因為它們更容易使用，並且由於OpenAI等LLM公司的工作的關係，越來越安全和更符合需求。
因此，本課程將專注於指令調整LLMs的最佳實踐，我們建議您在大多數應用程序中使用它。
在繼續之前，我只想對貢獻材料的OpenAI和DeepLearning.ai團隊表示感謝，Izzy和我將在此短期課程中展示他們的貢獻。
我非常感謝OpenAI的Andrew Main、Joe Palermo、Boris Power、Ted Sanders和Lillian Weng，他們積極參與了我們的材料討論，審查材料，編制課程大綱。
我還感謝Geoff Ladwig、Eddy Shyu和Tommy Nelson在深度學習方面的工作。
當您使用指令調整LLMs時，想像給另一個人指令，例如智者，但他不知道您的任務細節。
所以當LLMs不工作時，有時是因為指令不夠清晰。
例如：如果你想要寫一些關於阿蘭·圖靈的內容，除此之外，還需清楚表明你想要的內容是重點放在他的科學工作上還是個人生活上，或是他在歷史中扮演的角色或其他內容。
如果你指定了文章的語氣，它應該像專業記者寫的一樣嗎？還是更像是給朋友留的隨意筆記，希望OMS能幫你生成你想要的內容？當然，如果你設想你要求一個新畢業的大學生幫你完成這個任務，如果你能預先指定他們應該閱讀哪些文本片段來寫這篇關於阿蘭·圖靈的文章，那就更好了。
在下一個視頻中，你會看到如何明確和具體，這是提示OMS的重要原則，你還會學到另一個提示原則，即給LLM時間思考。
現在，讓我們繼續下一個視頻。
